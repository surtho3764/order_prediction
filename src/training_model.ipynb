{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8fa2e46",
   "metadata": {},
   "source": [
    "# training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8daedc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "# model\n",
    "import lightgbm\n",
    "import xgboost\n",
    "# 使用GridSearchCV針對RandomForestClassifier進行模型參數調校\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3200e0",
   "metadata": {},
   "source": [
    "# 獲取訓練和測試數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_sql(train_sql)\n",
    "test_data = read_sql(test_sql)\n",
    "\n",
    "\n",
    "features_columns = [col for col in train_data.columns if col not in ['user_id','label']]\n",
    "train = train_data[features_columns].values\n",
    "test = test_data[features_columns].values\n",
    "target =train_data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc244b6",
   "metadata": {},
   "source": [
    "# 分類模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04f436",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d19143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用GridSearchCV針對RandomForestClassifier進行模型參數調校\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.5, random_state=0)\n",
    "\n",
    "# model \n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "\n",
    "tuned_parameters = {\n",
    "                    'n_estimators': [50, 100, 200]\n",
    "#                     ,'criterion': ['gini', 'entropy']\n",
    "#                     ,'max_depth': [2, 5]\n",
    "#                     ,'max_features': ['log2', 'sqrt', 'int']\n",
    "#                     ,'bootstrap': [True, False]\n",
    "#                     ,'warm_start': [True, False]\n",
    "                    }\n",
    "\n",
    "scores = ['precision']\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(clf, tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    print(\"clf.cv_results result:\")\n",
    "    print()\n",
    "    print(clf.cv_results_)\n",
    "    \n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    # clf.predict(X_test):Call predict on the estimator with the best found parameters.\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    # classification_report(y_true, y_pred):Build a text report showing the main classification metrics.\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bfac1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed845c47",
   "metadata": {},
   "source": [
    "## VOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fea411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用集成學習中VOTE投票法，用多個弱學習器模型進行訓練\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "y = target\n",
    "\n",
    "# weak classifier:1 LogisticRegression\n",
    "clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)\n",
    "\n",
    "# weak classifier:2 RandomForestClassifier\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "\n",
    "# weak classifier:3 GaussianNB\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331c603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c20f53f",
   "metadata": {},
   "source": [
    "## lightgbm (lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit lightgbm model\n",
    "import lightgbm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "clf = lightgbm\n",
    "\n",
    "train_matrix = clf.Dataset(X_train, label=y_train)\n",
    "test_matrix = clf.Dataset(X_test, label=y_test)\n",
    "params = {\n",
    "          'boosting_type': 'gbdt',\n",
    "          #'boosting_type': 'dart',\n",
    "          'objective': 'multiclass',\n",
    "          'metric': 'multi_logloss',\n",
    "          'min_child_weight': 1.5,\n",
    "          'num_leaves': 2**5,\n",
    "          'lambda_l2': 10,\n",
    "          'subsample': 0.7,\n",
    "          'colsample_bytree': 0.7,\n",
    "          'colsample_bylevel': 0.7,\n",
    "          'learning_rate': 0.03,\n",
    "          'tree_method': 'exact',\n",
    "          'seed': 2017,\n",
    "          \"num_class\": 2,\n",
    "          'silent': True,\n",
    "          }\n",
    "num_round = 10000\n",
    "early_stopping_rounds = 100\n",
    "model = clf.train(params, \n",
    "                  train_matrix,\n",
    "                  num_round,\n",
    "                  valid_sets=test_matrix,\n",
    "                  early_stopping_rounds=early_stopping_rounds)\n",
    "pre= model.predict(X_valid,num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a293bb2",
   "metadata": {},
   "source": [
    "## xgboost (xgb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b19a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix xgboost model\n",
    "import xgboost\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "clf = xgboost\n",
    "\n",
    "train_matrix = clf.DMatrix(X_train, label=y_train, missing=-1)\n",
    "test_matrix = clf.DMatrix(X_test, label=y_test, missing=-1)\n",
    "z = clf.DMatrix(X_valid, label=y_valid, missing=-1)\n",
    "params = {'booster': 'gbtree',\n",
    "          'objective': 'multi:softprob',\n",
    "          'eval_metric': 'mlogloss',\n",
    "          'gamma': 1,\n",
    "          'min_child_weight': 1.5,\n",
    "          'max_depth': 5,\n",
    "          'lambda': 100,\n",
    "          'subsample': 0.7,\n",
    "          'colsample_bytree': 0.7,\n",
    "          'colsample_bylevel': 0.7,\n",
    "          'eta': 0.03,\n",
    "          'tree_method': 'exact',\n",
    "          'seed': 2017,\n",
    "          \"num_class\": 2\n",
    "          }\n",
    "\n",
    "num_round = 10000\n",
    "early_stopping_rounds = 100\n",
    "watchlist = [(train_matrix, 'train'),\n",
    "             (test_matrix, 'eval')\n",
    "             ]\n",
    "model = clf.train(params,\n",
    "                  train_matrix,\n",
    "                  num_boost_round=num_round,\n",
    "                  evals=watchlist,\n",
    "                  early_stopping_rounds=early_stopping_rounds\n",
    "                  )\n",
    "pre = model.predict(z,ntree_limit=model.best_ntree_limit)\n",
    "print('score : ', np.mean((pre[:,1]>0.3)==y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55dec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede9ffcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
