{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b3b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ed7e525",
   "metadata": {},
   "source": [
    "# feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8860e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import  sys,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import gc\n",
    "from collections import Counter\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Countvector, TF-IDF feature_extraction library\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a1e797",
   "metadata": {},
   "source": [
    "# 數據壓縮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295aeb3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2  #總共花多少MB\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes  # 各欄位資料類型\n",
    "        if col_type in numerics:  # 欄位類型是數值型類型\n",
    "            c_min = df[col].min() # 如果是數值型的話，找出最小的值\n",
    "            c_max = df[col].max()  # 如果是數值型的話，找出最大的值\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)   # 如果欄位是屬於np.int8就將這欄位的資料類型轉換成int8\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else: # 欄位類型是字串型類型\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage before optimization is:{:.2f} MB\".format(start_mem))\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8684bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = read_sql(train_sql)\n",
    "test_data = read_sql(test_sql)\n",
    "user_info = read_sql(user_info_sql).drop_duplicates()\n",
    "user_log = read_sql(user_los_sql).rename(columns = {\"seller_id\" : 'merchant_id'})\n",
    "\n",
    "train_data = reduce_mem_usage(train_data)\n",
    "test_data = reduce_mem_usage(test_data)\n",
    "\n",
    "user_info = reduce_mem_usage(user_info).drop_duplicates()\n",
    "user_log = reduce_mem_usage(user_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca802a3f",
   "metadata": {},
   "source": [
    "# 合併資訊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b5d4c7",
   "metadata": {},
   "source": [
    "## 處理Null和inf的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eff7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 處理Null和inf的資料\n",
    "def get_matrix(data):\n",
    "    where_are_nan = np.isnan(data)\n",
    "    where_are_inf = np.isnan(data)\n",
    "    data[where_are_nan] = 0\n",
    "    data[where_are_inf] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51573d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = get_matrix(np.float_(x_train))\n",
    "\n",
    "x_train = np.float_(x_train)\n",
    "\n",
    "y_train = np.int_(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd8998",
   "metadata": {},
   "source": [
    "## 合併資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1d8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_join_func = lambda x: \" \".join([str(i) for i in x])\n",
    "\n",
    "\n",
    "agg_dict = {\n",
    "            'item_id' : list_join_func,\t\n",
    "            'cat_id' : list_join_func,\n",
    "            'seller_id' : list_join_func,\n",
    "            'brand_id' : list_join_func,\n",
    "            'time_stamp' : list_join_func,\n",
    "            'action_type' : list_join_func\n",
    "        }\n",
    "\n",
    "rename_dict = {\n",
    "            'item_id' : 'item_path',\n",
    "            'cat_id' : 'cat_path',\n",
    "            'seller_id' : 'seller_path',\n",
    "            'brand_id' : 'brand_path',\n",
    "            'time_stamp' : 'time_stamp_path',\n",
    "            'action_type' : 'action_type_path'\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0748fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log_path = user_log.groupby('user_id').agg(agg_dict).reset_index().rename(columns=rename_dict)\n",
    "all_data = train_data.append(test_data)\n",
    "all_data_path = train_data.merge(user_log_path,on='user_id')\n",
    "gc.collect()\n",
    "del user_log\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3bd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2dc4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eaa7416",
   "metadata": {},
   "source": [
    "# 使用者歷程中，找出統計特徵extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596a70f5",
   "metadata": {},
   "source": [
    "## 統計特徵函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc6f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnt_(x):\n",
    "    try:\n",
    "        return len(x.split(' '))\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def nunique_(x):\n",
    "    try:\n",
    "        return len(set(x.split(' ')))\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "def max_(x):\n",
    "    try:\n",
    "        return np.max([int(i) for i in x.split(' ')])\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "def min_(x):\n",
    "    try:\n",
    "        return np.min([int(i) for i in x.split(' ')])\n",
    "    except:\n",
    "        return -1 \n",
    "    \n",
    "def std_(x):\n",
    "    try:\n",
    "        return np.std([float(i) for i in x.split(' ')])\n",
    "    except:\n",
    "        return -1 \n",
    "\n",
    "def most_n(x, n):\n",
    "    try:\n",
    "        return Counter(x.split(' ')).most_common(n)[n-1][0]\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def most_n_cnt(x, n):\n",
    "    try:\n",
    "        return Counter(x.split(' ')).most_common(n)[n-1][1]\n",
    "    except:\n",
    "        return -1   \n",
    "\n",
    "\n",
    "def user_cnt(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(cnt_)\n",
    "    return df_data\n",
    "\n",
    "def user_nunique(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(nunique_)\n",
    "    return df_data\n",
    "\n",
    "def user_max(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(max_)\n",
    "    return df_data\n",
    "\n",
    "\n",
    "def user_min(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(min_)\n",
    "    return df_data\n",
    "\n",
    "def user_std(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(std_)\n",
    "    return df_data\n",
    "\n",
    "def user_most_n(df_data, single_col, name, n=1):\n",
    "    func = lambda x: most_n(x, n)\n",
    "    df_data[name] = df_data[single_col].apply(func)\n",
    "    return df_data\n",
    "\n",
    "def user_most_n_cnt(df_data, single_col, name, n=1):\n",
    "    func = lambda x: most_n_cnt(x, n)\n",
    "    df_data[name] = df_data[single_col].apply(func)\n",
    "    return df_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857e0933",
   "metadata": {},
   "source": [
    "## extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b544a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = user_cnt(all_data,  'seller_path', 'user_cnt')\n",
    "all_data = user_nunique(all_data,  'seller_path', 'seller_nunique')\n",
    "all_data = user_nunique(all_data,  'cat_path', 'cat_nunique')\n",
    "all_data = user_nunique(all_data,  'brand_path', 'brand_nunique')\n",
    "all_data = user_nunique(all_data,  'item_path', 'item_nunique')\n",
    "all_data = user_nunique(all_data,  'time_stamp_path', 'time_stamp_nunique')\n",
    "all_data = user_nunique(all_data,  'action_type_path', 'action_type_nunique')\n",
    "\n",
    "all_data = user_max(all_data,  'action_type_path', 'time_stamp_max')\n",
    "all_data = user_min(all_data,  'action_type_path', 'time_stamp_min')\n",
    "all_data = user_std(all_data,  'action_type_path', 'time_stamp_std')\n",
    "all_data['time_stamp_range'] = all_data['time_stamp_max'] - all_data['time_stamp_min']\n",
    "\n",
    "all_data = user_most_n(all_data, 'seller_path', 'seller_most_1', n=1)\n",
    "all_data = user_most_n(all_data, 'cat_path', 'cat_most_1', n=1)\n",
    "all_data = user_most_n(all_data, 'brand_path', 'brand_most_1', n=1)\n",
    "all_data = user_most_n(all_data, 'action_type_path', 'action_type_1', n=1)\n",
    "all_data = user_most_n_cnt(all_data, 'seller_path', 'seller_most_1_cnt', n=1)\n",
    "all_data = user_most_n_cnt(all_data, 'cat_path', 'cat_most_1_cnt', n=1)\n",
    "all_data = user_most_n_cnt(all_data, 'brand_path', 'brand_most_1_cnt', n=1)\n",
    "all_data = user_most_n_cnt(all_data, 'action_type_path', 'action_type_1_cnt', n=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5689945a",
   "metadata": {},
   "source": [
    "# 店家相關的特徵extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b6598",
   "metadata": {},
   "source": [
    "## 店家相關的特徵函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4d4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_cnt_(df_data, columns_list, action_type):\n",
    "    try:\n",
    "        data_dict = {}\n",
    "        col_list = copy.deepcopy(columns_list)\n",
    "        if action_type != None:\n",
    "            col_list += ['action_type_path']\n",
    "\n",
    "        for col in col_list:\n",
    "            data_dict[col] = df_data[col].split(' ')\n",
    "        path_len = len(data_dict[col])\n",
    "        \n",
    "\n",
    "        data_out = []\n",
    "        for i_ in range(path_len):\n",
    "            data_txt = ''\n",
    "            for col_ in columns_list:\n",
    "                if data_dict['action_type_path'][i_] == action_type:\n",
    "                    data_txt += '_' + data_dict[col_][i_]\n",
    "            data_out.append(data_txt)\n",
    "\n",
    "        return len(data_out)  \n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def col_nuique_(df_data, columns_list, action_type):\n",
    "    try:\n",
    "        data_dict = {}\n",
    "\n",
    "        col_list = copy.deepcopy(columns_list)\n",
    "        if action_type != None:\n",
    "            col_list += ['action_type_path']\n",
    "\n",
    "        for col in col_list:\n",
    "            data_dict[col] = df_data[col].split(' ')\n",
    "            \n",
    "\n",
    "        path_len = len(data_dict[col])\n",
    "\n",
    "        data_out = []\n",
    "        for i_ in range(path_len):\n",
    "            data_txt = ''\n",
    "            for col_ in columns_list:\n",
    "                if data_dict['action_type_path'][i_] == action_type:\n",
    "                    data_txt += '_' + data_dict[col_][i_]\n",
    "            data_out.append(data_txt)\n",
    "        \n",
    "        return len(set(data_out))\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "\n",
    "def user_col_cnt(df_data, columns_list, action_type, name):\n",
    "    df_data[name] = df_data.apply(lambda x: col_cnt_(x, columns_list, action_type), axis=1)\n",
    "    return df_data\n",
    "\n",
    "def user_col_nunique(df_data, columns_list, action_type, name):\n",
    "    df_data[name] = df_data.apply(lambda x: col_nuique_(x, columns_list, action_type), axis=1)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309cd02",
   "metadata": {},
   "source": [
    "## extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00349494",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = user_col_cnt(all_data,  ['seller_path'], '0', 'user_cnt_0')\n",
    "\n",
    "all_data = user_col_cnt(all_data,  ['seller_path'], '1', 'user_cnt_1')\n",
    "\n",
    "all_data = user_col_cnt(all_data,  ['seller_path'], '2', 'user_cnt_2')\n",
    "\n",
    "all_data = user_col_cnt(all_data,  ['seller_path'], '3', 'user_cnt_3')\n",
    "\n",
    "all_data = user_col_nunique(all_data,  ['seller_path'], '0', 'seller_nunique_0')\n",
    "\n",
    "all_data = user_col_cnt(all_data,  ['seller_path', 'item_path'], '0', 'user_cnt_0')\n",
    "\n",
    "all_data = user_col_nunique(all_data,  ['seller_path', 'item_path'], '0', 'seller_nunique_0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba74a4",
   "metadata": {},
   "source": [
    "\n",
    "# 利用Countvector和TF-IDF提取特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d882d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVec = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range=(1, 1), max_features=100)\n",
    "\n",
    "columns_list = ['seller_path', 'cat_path', 'brand_path', 'action_type_path', 'item_path', 'time_stamp_path']\n",
    "\n",
    "for i, col in enumerate(columns_list):\n",
    "    all_data_test[col] = all_data_test[col].astype(str)\n",
    "    tfidfVec.fit(all_data_test[col])\n",
    "    data_ = tfidfVec.transform(all_data_test[col])\n",
    "    if i == 0:\n",
    "        data_cat = data_\n",
    "    else:\n",
    "        data_cat = sparse.hstack((data_cat, data_))\n",
    "    print(data_cat.shape)\n",
    "\n",
    "df_tfidf = pd.DataFrame(data_cat.toarray())\n",
    "\n",
    "df_tfidf.columns = ['tfidf_' + str(i) for i in df_tfidf.columns]\n",
    "\n",
    "all_data = pd.concat([all_data, df_tfidf],axis=1)\n",
    "len(all_data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92347e2",
   "metadata": {},
   "source": [
    "# 得到特徵萃取後的train和test資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "x_train_data = all_data_test[~all_data_test['label'].isna()]\n",
    "\n",
    "\n",
    "x_train = x_train_data.loc[:,features_columns].values\n",
    "\n",
    "y_train = x_train_data.loc[:,'label'].values\n",
    "\n",
    "# test data\n",
    "x_test_data = all_data_test[all_data_test['label'].isna()]\n",
    "\n",
    "x_test = x_test_data.loc[:,features_columns].values\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09314f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
